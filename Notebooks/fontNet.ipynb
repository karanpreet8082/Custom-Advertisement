{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e917da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting utils\n",
      "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
      "Installing collected packages: utils\n",
      "Successfully installed utils-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df697fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import glob\n",
    "import numpy\n",
    "import os\n",
    "import tensorflow\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Input\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.models import Model\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fcf0b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP        = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "RANDOM_SEED      = 99999999\n",
    "\n",
    "ARCHITECTURE     = 'colornet'\n",
    "\n",
    "TRAIN_IMAGES_DIR = 'datasets/colornet/train/'\n",
    "VALID_IMAGES_DIR = 'datasets/colornet/valid/'\n",
    "TEST_IMAGES_DIR  = 'datasets/colornet/test/'\n",
    "OUTPUT_DIR       = 'output/{}/{}/'.format(ARCHITECTURE, TIMESTAMP)\n",
    "\n",
    "IMAGE_FILE_EXT   = '.jpg'\n",
    "\n",
    "FUNCTION_OPTIM   = 'adam'\n",
    "FUNCTION_LOSS    = 'mae'\n",
    "\n",
    "INPUT_IMAGE_SIZE = (64, 64)\n",
    "\n",
    "SCALE_COEFF_IMG  = 1.\n",
    "BATCH_SIZE       = 64\n",
    "NUM_EPOCHS       = 10\n",
    "\n",
    "VERBOSE_LEVEL    = 2\n",
    "\n",
    "SAVE_IMAGES      = False\n",
    "SHOW_IMAGES      = True\n",
    "MAX_IMAGES       = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c839bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "    def __init__(self, image_dir_input1, image_dir_input2, image_dir_output,\n",
    "                 image_ext='.jpg', target_shape=(64, 64), rescale=1.,\n",
    "                 batch_size=1, shuffle=True, seed=None):\n",
    "        numpy.random.seed(seed)\n",
    "        self._imdir_in1 = image_dir_input1\n",
    "        self._imdir_in2 = image_dir_input2\n",
    "        self._imdir_out = image_dir_output\n",
    "        self._imext = image_ext\n",
    "        self._shape = target_shape\n",
    "        self._scale = rescale\n",
    "        self._batch = batch_size\n",
    "        self._shake = shuffle\n",
    "        self._files = sorted([os.path.split(path)[-1] for path in \\\n",
    "                              glob.glob('{}/*{}'.format(image_dir_input1, image_ext))])\n",
    "        self._steps = int(len(self._files) / self._batch + 0.5)\n",
    "        self._index = 0\n",
    "        if shuffle:\n",
    "            numpy.random.shuffle(self._files)\n",
    "    \n",
    "    def flow(self):\n",
    "        while True:\n",
    "            x1 = []\n",
    "            x2 = []\n",
    "            y1 = []\n",
    "            endidx = self._index + self._batch\n",
    "            subset = self._files[self._index:endidx]\n",
    "            self._index = endidx if endidx < len(self._files) else 0\n",
    "            if self._shake:\n",
    "                numpy.random.shuffle(subset)\n",
    "            for file in subset:\n",
    "                file_input1 = os.path.join(self._imdir_in1, file)\n",
    "                file_input2 = os.path.join(self._imdir_in2, file)\n",
    "                file_output = os.path.join(self._imdir_out, file)\n",
    "                try:\n",
    "                    input1 = Image.open(file_input1).convert('RGB').resize(self._shape)\n",
    "                    input1 = numpy.asarray(input1, dtype=numpy.uint8)\n",
    "                    input1 = numpy.atleast_3d(input1)\n",
    "                    input2 = Image.open(file_input2).convert('L').resize(self._shape)\n",
    "                    input2 = numpy.asarray(input2, dtype=numpy.uint8)\n",
    "                    input2 = numpy.atleast_3d(input2)\n",
    "                    output = Image.open(file_output).convert('RGB').resize(self._shape)\n",
    "                    output = numpy.asarray(output, dtype=numpy.uint8)\n",
    "                    output = numpy.atleast_3d(output)\n",
    "                except:\n",
    "                    continue\n",
    "                x1.append(input1)\n",
    "                x2.append(input2)\n",
    "                y1.append(output)\n",
    "            x1 = numpy.asarray(x1, dtype=numpy.float32) * self._scale\n",
    "            x2 = numpy.asarray(x2, dtype=numpy.float32) * self._scale\n",
    "            y1 = numpy.asarray(y1, dtype=numpy.float32) * self._scale\n",
    "            yield [[x1, x2], y1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "336ad721",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Colornet(object):\n",
    "    def __new__(self, input_shapes, optimizer, loss, weights=None):\n",
    "        # build network\n",
    "        x1 = Input(input_shapes[0])\n",
    "        x2 = Input(input_shapes[1])\n",
    "        \n",
    "        y1 = Convolution2D(filters=64, kernel_size=(3, 3), padding='same')(x1)\n",
    "        y1 = LeakyReLU(alpha=0.2)(y1)\n",
    "        y1 = BatchNormalization()(y1)\n",
    "        \n",
    "        y2 = Convolution2D(filters=64, kernel_size=(3, 3), padding='same')(x2)\n",
    "        y2 = LeakyReLU(alpha=0.2)(y2)\n",
    "        y2 = BatchNormalization()(y2)\n",
    "        \n",
    "        y = Concatenate()([y1, y2])\n",
    "        \n",
    "        y = Convolution2D(filters=64, kernel_size=(3, 3), padding='same')(y)\n",
    "        y = LeakyReLU(alpha=0.2)(y)\n",
    "        y = Convolution2D(filters=64, kernel_size=(3, 3), padding='same')(y)\n",
    "        y = LeakyReLU(alpha=0.2)(y)\n",
    "        \n",
    "        y = MaxPooling2D(pool_size=(2, 2))(y)\n",
    "        \n",
    "        y = Convolution2D(filters=128, kernel_size=(3, 3), padding='same')(y)\n",
    "        y = LeakyReLU(alpha=0.2)(y)\n",
    "        y = Convolution2D(filters=128, kernel_size=(3, 3), padding='same')(y)\n",
    "        y = LeakyReLU(alpha=0.2)(y)\n",
    "        \n",
    "        y = MaxPooling2D(pool_size=(2, 2))(y)\n",
    "        \n",
    "        y = Convolution2D(filters=256, kernel_size=(3, 3), padding='same')(y)\n",
    "        y = LeakyReLU(alpha=0.2)(y)\n",
    "        y = Convolution2D(filters=256, kernel_size=(3, 3), padding='same')(y)\n",
    "        y = LeakyReLU(alpha=0.2)(y)\n",
    "        y = Convolution2D(filters=256, kernel_size=(3, 3), padding='same')(y)\n",
    "        y = LeakyReLU(alpha=0.2)(y)\n",
    "        \n",
    "        y = UpSampling2D(size=(2, 2))(y)\n",
    "        y = Convolution2D(filters=128, kernel_size=(3, 3), padding='same')(y)\n",
    "        y = LeakyReLU(alpha=0.2)(y)\n",
    "        \n",
    "        y = UpSampling2D(size=(2, 2))(y)\n",
    "        y = Convolution2D(filters=64, kernel_size=(3, 3), padding='same')(y)\n",
    "        y = LeakyReLU(alpha=0.2)(y)\n",
    "        \n",
    "        y = Convolution2D(filters=3, kernel_size=(3, 3), padding='same')(y)\n",
    "        y = LeakyReLU(alpha=0.2)(y)\n",
    "        \n",
    "        # compile network\n",
    "        model = Model(inputs=[x1, x2], outputs=y)\n",
    "        model.compile(optimizer=optimizer, loss=loss)\n",
    "        \n",
    "        # optionally load existing weights into network\n",
    "        try:\n",
    "            if not weights is None:\n",
    "                model.load_weights(weights)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9ef8bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorflow_version():\n",
    "    return int(tensorflow.__version__.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37aec291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # setup seed for random number generators for reproducibility\n",
    "    numpy.random.seed(RANDOM_SEED)\n",
    "    \n",
    "    if tensorflow_version() == 2:\n",
    "        tensorflow.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tensorflow.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    # setup paths\n",
    "    mdl_dir = os.path.join(OUTPUT_DIR, 'models')\n",
    "    log_dir = os.path.join(OUTPUT_DIR, 'logs')\n",
    "    cpt_dir = os.path.join(OUTPUT_DIR, 'checkpoints')\n",
    "    pro_dir = os.path.join(OUTPUT_DIR, 'progress')\n",
    "    \n",
    "    setup_flag = True\n",
    "    for directory in [TRAIN_IMAGES_DIR, VALID_IMAGES_DIR]:\n",
    "        if not os.path.isdir(directory):\n",
    "            print('[INFO] Data directory not found at {}'.format(directory))\n",
    "            setup_flag = False\n",
    "    if not os.path.isdir(TEST_IMAGES_DIR):\n",
    "        print('[INFO] Data directory not found at {}'.format(directory))\n",
    "    for directory in [OUTPUT_DIR, mdl_dir, log_dir, cpt_dir, pro_dir]:\n",
    "        if not os.path.isdir(directory):\n",
    "            os.makedirs(directory)\n",
    "        elif len(glob.glob(os.path.join(directory, '*.*'))) > 0:\n",
    "            print('[INFO] Output directory {} must be empty'.format(directory))\n",
    "            setup_flag = False\n",
    "    if not setup_flag:\n",
    "        return\n",
    "    \n",
    "    mdl_file = os.path.join(mdl_dir, '{}.json'.format(ARCHITECTURE))\n",
    "    log_file = os.path.join(log_dir, '{}_training.csv'.format(ARCHITECTURE))\n",
    "    cpt_file_best = os.path.join(cpt_dir, '{}_weights_best.h5'.format(ARCHITECTURE))\n",
    "    cpt_file_last = os.path.join(cpt_dir, '{}_weights_last.h5'.format(ARCHITECTURE))\n",
    "    \n",
    "    # initialize train data generator\n",
    "    train_datagen = DataGenerator(image_dir_input1=TRAIN_IMAGES_DIR + '/input_color/',\n",
    "                                  image_dir_input2=TRAIN_IMAGES_DIR + '/input_mask/',\n",
    "                                  image_dir_output=TRAIN_IMAGES_DIR + '/output_color/',\n",
    "                                  image_ext=IMAGE_FILE_EXT,\n",
    "                                  target_shape=INPUT_IMAGE_SIZE,\n",
    "                                  rescale=SCALE_COEFF_IMG,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True,\n",
    "                                  seed=RANDOM_SEED)\n",
    "    \n",
    "    # initialize valid data generator\n",
    "    valid_datagen = DataGenerator(image_dir_input1=VALID_IMAGES_DIR + '/input_color/',\n",
    "                                  image_dir_input2=VALID_IMAGES_DIR + '/input_mask/',\n",
    "                                  image_dir_output=VALID_IMAGES_DIR + '/output_color/',\n",
    "                                  image_ext=IMAGE_FILE_EXT,\n",
    "                                  target_shape=INPUT_IMAGE_SIZE,\n",
    "                                  rescale=SCALE_COEFF_IMG,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True,\n",
    "                                  seed=RANDOM_SEED)\n",
    "    \n",
    "    # build and serialize network\n",
    "    print('[INFO] Building network... ', end='')\n",
    "    colornet = Colornet(input_shapes=[INPUT_IMAGE_SIZE + (3,), INPUT_IMAGE_SIZE + (1,)],\n",
    "                        optimizer=FUNCTION_OPTIM,\n",
    "                        loss=FUNCTION_LOSS,\n",
    "                        weights=None)\n",
    "    print('done')\n",
    "    colornet.summary()\n",
    "    \n",
    "    with open(mdl_file, 'w') as file:\n",
    "        file.write(colornet.to_json())\n",
    "    \n",
    "    # create callbacks\n",
    "    csv_logs = CSVLogger(filename=log_file, append=True)\n",
    "    cpt_best = ModelCheckpoint(filepath=cpt_file_best,\n",
    "                               monitor='val_loss',\n",
    "                               verbose=1,\n",
    "                               save_best_only=True,\n",
    "                               save_weights_only=True)\n",
    "    cpt_last = ModelCheckpoint(filepath=cpt_file_last,\n",
    "                               monitor='val_loss',\n",
    "                               verbose=0,\n",
    "                               save_best_only=False,\n",
    "                               save_weights_only=True)\n",
    "    progress = ProgressMonitor(image_dir_input1=TEST_IMAGES_DIR + '/input_color/',\n",
    "                               image_dir_input2=TEST_IMAGES_DIR + '/input_mask/',\n",
    "                               image_dir_output=TEST_IMAGES_DIR + '/output_color/',\n",
    "                               save_to_dir=pro_dir,\n",
    "                               image_ext=IMAGE_FILE_EXT,\n",
    "                               rescale=SCALE_COEFF_IMG,\n",
    "                               thumbnail_size=(64, 64),\n",
    "                               save=SAVE_IMAGES,\n",
    "                               show=SHOW_IMAGES,\n",
    "                               max_images=MAX_IMAGES)\n",
    "    \n",
    "    # train network\n",
    "    colornet.fit(\n",
    "                           steps_per_epoch=train_datagen._steps,\n",
    "                           epochs=NUM_EPOCHS,\n",
    "                           callbacks=[csv_logs, cpt_best, cpt_last, progress],\n",
    "                           validation_data=valid_datagen.flow(),\n",
    "                           validation_steps=valid_datagen._steps,\n",
    "                           verbose=VERBOSE_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c670b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMonitor(Callback):\n",
    "    def __init__(self, image_dir_input1, image_dir_input2, image_dir_output,\n",
    "                 save_to_dir, image_ext='.jpg', rescale=1.,\n",
    "                 thumbnail_size=(64, 64), save=True, show=False, max_images=10):\n",
    "        self._imdir_in1 = image_dir_input1\n",
    "        self._imdir_in2 = image_dir_input2\n",
    "        self._imdir_out = image_dir_output\n",
    "        self._imdir_dmp = save_to_dir\n",
    "        self._img_ext = image_ext\n",
    "        self._rescale = rescale\n",
    "        self._tn_size = thumbnail_size\n",
    "        self._im_save = save\n",
    "        self._im_show = show\n",
    "        self._max_img = max_images\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        images_all = []\n",
    "        images_in1 = sorted(glob.glob(self._imdir_in1 + '/*' + self._img_ext))[:self._max_img]\n",
    "        images_in2 = sorted(glob.glob(self._imdir_in2 + '/*' + self._img_ext))[:self._max_img]\n",
    "        images_out = sorted(glob.glob(self._imdir_out + '/*' + self._img_ext))[:self._max_img]\n",
    "        for image_in1, image_in2, image_out in zip(images_in1, images_in2, images_out):\n",
    "            try:\n",
    "                img_in1 = Image.open(image_in1).convert('RGB')\n",
    "                img_in2 = Image.open(image_in2).convert('L')\n",
    "                img_out = Image.open(image_out).convert('RGB')\n",
    "                x1 = img_in1.resize(self.model.input_shape[0][1:3])\n",
    "                x1 = numpy.asarray(x1, dtype=numpy.float32) * self._rescale\n",
    "                x1 = numpy.atleast_3d(x1)\n",
    "                x1 = numpy.expand_dims(x1, axis=0)\n",
    "                x2 = img_in2.resize(self.model.input_shape[1][1:3])\n",
    "                x2 = numpy.asarray(x2, dtype=numpy.float32) * self._rescale\n",
    "                x2 = numpy.atleast_3d(x2)\n",
    "                x2 = numpy.expand_dims(x2, axis=0)\n",
    "                y1 = self.model.predict([x1, x2])\n",
    "                y1 = numpy.squeeze(y1)\n",
    "                y1 = numpy.asarray(y1 / self._rescale, dtype=numpy.uint8)\n",
    "                img_gen = Image.fromarray(y1)\n",
    "                img_gen = self._postprocess_image(img_gen, img_in2)\n",
    "                images_all.append([img_in1, img_in2, img_out, img_gen])\n",
    "            except:\n",
    "                continue\n",
    "        images_all = self._combine_images(images_all, self._tn_size, border_width=4, padding=20)\n",
    "        if self._im_save:\n",
    "            impath = self._imdir_dmp + '/epoch_{}.jpg'.format(epoch + 1)\n",
    "            self._save_image(impath, images_all)\n",
    "        if self._im_show:\n",
    "            imdesc = 'Epoch {} - Top to Bottom: Source Color | Target Mask | Target Color | Generated Color'.format(epoch + 1)\n",
    "            self._show_image(images_all, imdesc)\n",
    "    \n",
    "    def _postprocess_image(self, image, mask):\n",
    "        image_pped = Image.new(image.mode, image.size)\n",
    "        image_mask = mask.convert('L').resize(image.size)\n",
    "        image_pped.paste(image, (0, 0), image_mask)\n",
    "        return image_pped\n",
    "    \n",
    "    def _combine_images(self, images=[], size=(64, 64), bg_color=(0, 0, 0),\n",
    "                        border_color=(255, 255, 255), border_width=0, padding=0):\n",
    "        for i, result in enumerate(images):\n",
    "            w1 = size[0] + 2 * border_width\n",
    "            h1 = size[1] * len(result) + 2 * border_width\n",
    "            bg = Image.new('RGB', (w1, h1), border_color)\n",
    "            for j, image in enumerate(result):\n",
    "                x1 = border_width\n",
    "                y1 = border_width + j * size[1]\n",
    "                fg = image.convert('RGB').resize(size, resample=Image.BILINEAR)\n",
    "                bg.paste(fg, (x1, y1))\n",
    "            images[i] = bg\n",
    "        w2 = len(images) * (w1 + padding) + padding\n",
    "        h2 = h1 + 2 * padding\n",
    "        bg = Image.new('RGB', (w2, h2), bg_color)\n",
    "        for k, image in enumerate(images):\n",
    "            x2 = k * (w1 + padding) + padding\n",
    "            y2 = padding\n",
    "            bg.paste(image, (x2, y2))\n",
    "        return bg\n",
    "    \n",
    "    def _save_image(self, filepath, image):\n",
    "        directory = os.path.dirname(filepath)\n",
    "        if not os.path.isdir(directory) and directory != '':\n",
    "            os.makedirs(directory)\n",
    "        image.save(filepath)\n",
    "    \n",
    "    def _show_image(self, image, title=None):\n",
    "        pyplot.figure(figsize=(image.width/100, image.height/100), dpi=100)\n",
    "        pyplot.axis('off')\n",
    "        if title:\n",
    "            pyplot.title(title)\n",
    "        pyplot.imshow(numpy.uint8(image))\n",
    "        pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c96bb73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Building network... done\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_15 (InputLayer)       [(None, 64, 64, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " input_16 (InputLayer)       [(None, 64, 64, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)          (None, 64, 64, 64)           1792      ['input_15[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)          (None, 64, 64, 64)           640       ['input_16[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu_60 (LeakyReLU)  (None, 64, 64, 64)           0         ['conv2d_60[0][0]']           \n",
      "                                                                                                  \n",
      " leaky_re_lu_61 (LeakyReLU)  (None, 64, 64, 64)           0         ['conv2d_61[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 64, 64, 64)           256       ['leaky_re_lu_60[0][0]']      \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 64, 64, 64)           256       ['leaky_re_lu_61[0][0]']      \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 64, 64, 128)          0         ['batch_normalization_10[0][0]\n",
      " )                                                                  ',                            \n",
      "                                                                     'batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)          (None, 64, 64, 64)           73792     ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_62 (LeakyReLU)  (None, 64, 64, 64)           0         ['conv2d_62[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)          (None, 64, 64, 64)           36928     ['leaky_re_lu_62[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_63 (LeakyReLU)  (None, 64, 64, 64)           0         ['conv2d_63[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooli  (None, 32, 32, 64)           0         ['leaky_re_lu_63[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)          (None, 32, 32, 128)          73856     ['max_pooling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " leaky_re_lu_64 (LeakyReLU)  (None, 32, 32, 128)          0         ['conv2d_64[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)          (None, 32, 32, 128)          147584    ['leaky_re_lu_64[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_65 (LeakyReLU)  (None, 32, 32, 128)          0         ['conv2d_65[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooli  (None, 16, 16, 128)          0         ['leaky_re_lu_65[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)          (None, 16, 16, 256)          295168    ['max_pooling2d_11[0][0]']    \n",
      "                                                                                                  \n",
      " leaky_re_lu_66 (LeakyReLU)  (None, 16, 16, 256)          0         ['conv2d_66[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)          (None, 16, 16, 256)          590080    ['leaky_re_lu_66[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_67 (LeakyReLU)  (None, 16, 16, 256)          0         ['conv2d_67[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)          (None, 16, 16, 256)          590080    ['leaky_re_lu_67[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_68 (LeakyReLU)  (None, 16, 16, 256)          0         ['conv2d_68[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_10 (UpSampli  (None, 32, 32, 256)          0         ['leaky_re_lu_68[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)          (None, 32, 32, 128)          295040    ['up_sampling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " leaky_re_lu_69 (LeakyReLU)  (None, 32, 32, 128)          0         ['conv2d_69[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_11 (UpSampli  (None, 64, 64, 128)          0         ['leaky_re_lu_69[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)          (None, 64, 64, 64)           73792     ['up_sampling2d_11[0][0]']    \n",
      "                                                                                                  \n",
      " leaky_re_lu_70 (LeakyReLU)  (None, 64, 64, 64)           0         ['conv2d_70[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)          (None, 64, 64, 3)            1731      ['leaky_re_lu_70[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_71 (LeakyReLU)  (None, 64, 64, 3)            0         ['conv2d_71[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2180995 (8.32 MB)\n",
      "Trainable params: 2180739 (8.32 MB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train()\n",
      "Cell \u001b[0;32mIn[50], line 95\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m progress \u001b[38;5;241m=\u001b[39m ProgressMonitor(image_dir_input1\u001b[38;5;241m=\u001b[39mTEST_IMAGES_DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/input_color/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     84\u001b[0m                            image_dir_input2\u001b[38;5;241m=\u001b[39mTEST_IMAGES_DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/input_mask/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     85\u001b[0m                            image_dir_output\u001b[38;5;241m=\u001b[39mTEST_IMAGES_DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/output_color/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m                            show\u001b[38;5;241m=\u001b[39mSHOW_IMAGES,\n\u001b[1;32m     92\u001b[0m                            max_images\u001b[38;5;241m=\u001b[39mMAX_IMAGES)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# train network\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m colornet\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     96\u001b[0m                        steps_per_epoch\u001b[38;5;241m=\u001b[39mtrain_datagen\u001b[38;5;241m.\u001b[39m_steps,\n\u001b[1;32m     97\u001b[0m                        epochs\u001b[38;5;241m=\u001b[39mNUM_EPOCHS,\n\u001b[1;32m     98\u001b[0m                        callbacks\u001b[38;5;241m=\u001b[39m[csv_logs, cpt_best, cpt_last, progress],\n\u001b[1;32m     99\u001b[0m                        validation_data\u001b[38;5;241m=\u001b[39mvalid_datagen\u001b[38;5;241m.\u001b[39mflow(),\n\u001b[1;32m    100\u001b[0m                        validation_steps\u001b[38;5;241m=\u001b[39mvalid_datagen\u001b[38;5;241m.\u001b[39m_steps,\n\u001b[1;32m    101\u001b[0m                        verbose\u001b[38;5;241m=\u001b[39mVERBOSE_LEVEL)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1105\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1102\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle input: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1107\u001b[0m             _type_name(x), _type_name(y)\n\u001b[1;32m   1108\u001b[0m         )\n\u001b[1;32m   1109\u001b[0m     )\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapter_cls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData adapters should be mutually exclusive for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandling inputs. Found multiple adapters \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[1;32m   1115\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f99b4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6fd3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df42bb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d6dadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee624f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9326cbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
